{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw7_21400646.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PASTANERD/HGU_PYNQ_Project/blob/master/hw7_21400646.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSAFccm4OPTx",
        "colab_type": "text"
      },
      "source": [
        "<div style=\"text-align:right\"> <h1> Machine Learning</h1> <h3> HW #7 </h3> <h4> 21400646 Lim Chae Eon </h4> </div>\n",
        "\n",
        "### Final Report: BNN(Binarized Neural Network)\n",
        "\n",
        "1. **Introduction**\n",
        "  1. BNN을 선택한 이유 현재 연구하고 있는 분야\n",
        "  1. BNN 요약\n",
        "1. **Algorithms and Implements BNN**\n",
        "  1. Parameter Binarization\n",
        "  1. Gradient Propagation in Binarized Neural Network\n",
        "  1. Binarized Fully Connected Layer\n",
        "  1. Binarized Neural Network\n",
        "  1. Training Code\n",
        "  1. Testing Code\n",
        "  1. Configuration and Datatsets\n",
        "1. **Reuslt(Comparing Accuracy)**\n",
        "  1. Training and Testing MNIST Datasets on Binarized Neural Network \n",
        "  1. Training and Testing MNIST Datasets on Deep Neural Network \n",
        "  1. Comparing the results\n",
        "1. **Appendix**\n",
        "1. **References**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbA7mMFdQMs5",
        "colab_type": "text"
      },
      "source": [
        "### 1\\. Introduction\n",
        "#### **BNN: Binarized Neural Network**\n",
        ">Binarized Neural Network는 Neural Network의 Weight(가중치)와 Activation(Activation function의 결과)가 Run-time 중에 bit로 구성되어있는 딥러닝 네트워크를 의미한다[1].\n",
        "\n",
        "딥러닝 네트워크를 이진화(Binarization)하는 방법은, Training이 끝난 후 결과로 얻은 Parameter를 이진화하거나, Training 과정에서 Propagation 중에 이진화를 처리하는 방법이 있다. 알려진 바로는, Training 과정에서 이진화를 하는 것이 더 좋은 결과를 얻는다고 한다. 부가적으로, Training 시 Binary Weight와 Binary Activation은 Parameter의 Gradient를 구하는데 사용할 수 있다.\n",
        "</br></br>\n",
        "#### **FPGA Accelerator for Deep Learning**\n",
        "FPGA는 일반적으로 ASIC 설계의 검증 및 테스트용으로 많이 사용되어왔으나, 최근 딥러닝의 발전과 함께 가속기로써 잠재된 영향력이 대두되고 있다. FPGA는 현장에서 재구성 가능한 하드웨어를 일컫는 말로, CPU나 GPU처럼 기능이 정해지지 않고, 프로그래밍으로 하드웨어의 기능을 조절할 수 있다. FPGA를 이용하여 가속기를 설계하면 GPU처럼 Deep Learning 연산을 가속시키는 것이 가능하다. 또한 GPU에 비해 훨씬 더 적은 전력을 소모하면서 GPU에 못지 않은 성능을 보여주고 있다[2].\n",
        "</br></br>\n",
        "#### **BNN and FPGA Accelerator on Embedded System**\n",
        "대부분의 컴퓨팅 하드웨어들은 기본적으로 논리 연산을 바탕으로 하고 있다. 그러나 Deep Learning에서 가장 많은 연산을 차지하는 Linear 연산의 경우 대부분 Parameter들이 32-bit Floating Point 로 처리된다. 부동소수점(Floating Point) 연산은 많은 메모리를 필요로 하며 처리될 데이터의 크기가 커짐으로써 연산의 부하를 높이게 된다. BNN은 Parameter들을 1-bit로 표현함으로써, 메모리 사용을 크게 줄이고, 동시에 Matrix Multiplication 같은 복잡한 연산을 Bitwise Operation으로 대체할 수 있게 한다. 이는 하드웨어의 퍼포먼스를 극대화하는 것으로 그치지 않고, FPGA 가속기로 하여금 리소스와 전력이 제한된 Embedded System에서 Deep Learning 연산을 가능하게 한다.\n",
        "</br></br>\n",
        "#### **보고서를 시작하며,**\n",
        "본 보고서는 이강교수님의 FPGA 가속기 연구실에서 **임베디드 환경에서 딥러닝 네트워크 추론을 위한 FPGA 가속기 설계** 연구에서 사용되는 BNN을 구현하고 이를 검증하는 것을 담았다. 저자가 속한 연구실은 연구에서 BNN을 이용하지만, BNN을 직접 연구하지 않기 때문에 이를 구현하는 과정은 보고서에서 처음 이루어졌다. 또한 연구에서 사용하던 BNN은 Theano, Lasagne 프레임워크 기반으로 구현되어 있었다. 따라서 이 보고서를 통해 PyTorch 기반에서 BNN을 새롭게 구현하고자 하였다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC2kHAypXb98",
        "colab_type": "text"
      },
      "source": [
        "### 2\\. Algorithms and Implements BNN\n",
        "\n",
        "#### 2.1. Parameter Binarization\n",
        "BNN에서 이진화 되는 Parameter는 Weight와 Activation이 있다. 기본적으로 이진화 법칙은 아래 식을 따른다[1].\n",
        "\n",
        "| Deterministic Binarization | Stochastic Binarization |\n",
        "| :---: | :---: |\n",
        "| $$x^b = Sign(x) =   \\begin{cases} +1  & \\quad \\text{if } x \\geq 0 \\\\\n",
        "    -1  & \\quad \\text{otherwise}\n",
        "  \\end{cases}$$ | $$ \n",
        "x^b =   \\begin{cases}\n",
        "    +1  & \\quad \\text{with probability } p =  \\sigma(x) \\\\\n",
        "    -1  & \\quad \\text{with probability } 1 - p\n",
        "  \\end{cases} \n",
        "$$ |\n",
        "\n",
        "</br>\n",
        "\n",
        "Stochastic Binarization에서 $Sign(x)$는 입력 x의 부호를 구하는 함수 $\\text{(Signum Function)}$이며, $\\sigma(x)는 \\text{ Hard Sigmoid function}$를 뜻하며, 정의는 아래와 같다.</br>\n",
        ">$\n",
        "  \\sigma(x) = clip(\\frac{x+1}{2} ,0, 1) = max(0, min(1, \\frac{x+1}{2}))\n",
        "$\n",
        "\n",
        "위 식에서 알 수 있듯이, Binary라고 하면 기본적인 표현법은 0 과 1이지만, 식에서 표현은 +1과 -1로 구성하고 있다. 이와 같이 표현하는 이유는, 컴퓨터에서 사용하는 데이터의 범위 표현 방법을 그대로 차용하기 때문이다. 예를 들어, C언어에서 int와 같은 경우 기본적으로 32bit로 구성되어 있으며, 부호를 표현하기 위해 $[-2^{15},~ ... ~, 2^{15}-1]$ 사이의 숫자를 표현할 수 있다. 마찬가지로 1bit의 Binary 표현법은 0과 1이지만, 컴퓨터 부호를 포함하여 표현하면 1과 -1로 볼 수 있다. 동시에 0과 1처럼 숫자의 범위가 2개 밖에 없기 때문에 연산 방식을 기존과 다르게 Bit operation을 적용할 수 있다.\n",
        "\n",
        "아래는, 앞서 설명한 이진화를 코드로 구현한 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4hu3u1HGtQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def HardSigmoid(tensor):\n",
        "    return tensor.add_(1).div_(2).add_(torch.rand(tensor.size()).add(-0.5)).clamp_(0,1).round().mul_(2).add_(-1)\n",
        "\n",
        "def Binarize(tensor,quant_mode='det'):\n",
        "  # Deterministic Method\n",
        "    if quant_mode=='det':\n",
        "        return tensor.sign()\n",
        "  # Stochastic Method        \n",
        "    else:\n",
        "        return HardSigmoid(tensor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_nv8_XWXrSb",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2. Gradients Propagation in Binary\n",
        "앞서 Deterministic Binarization에서, Parameter를 Sign($ x^b = Sign(x) $)를 이용하여 계산했다. Binary Parameter의 Gradient Propagation은 아래 식과 같이 표현할 수 있다[1]. \n",
        "\n",
        ">$\n",
        " g_x = g_{x^b} * 1_{|x|\\leq1} \\\\ \n",
        "$\n",
        "\n",
        "이 때, $1_{|x|\\leq1}$의 의미는 다음과 같다.\n",
        "\n",
        ">$\n",
        "1_{|x|\\leq1} = \\begin{cases}\n",
        "    1  & \\quad \\text{if } -1 \\leq x \\leq 1 \\\\\n",
        "    0  & \\quad \\text{otherwise}\n",
        "  \\end{cases}  \n",
        "$\n",
        "\n",
        "이는 _Hard Tanh_ 연산으로 표현할 수 있다.</br>\n",
        "![activation2](https://pytorch.org/docs/stable/_images/Hardtanh.png)\n",
        "\n",
        "\n",
        "이는 Hinton의 STE(Straight-Through Estimator)의 아이디어를 이용한 것이다. 즉, Sign 함수를 사용하게 되면, Sign 함수를 미분한 결과는 Delta 함수처럼 나타나기 때문에, Parameter 값이 조금이라도 크거나 작을 경우, Gradient가 Saturation 되는 경향이 쉽게 발생한다. 따라서 Parameter들이 |1| 보다 클 경우 이를 차단하는 방식을 사용하였다.\n",
        "(이는 Stochastic 에서도 동일하게 적용할 수 있다)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXsOpDcbLIKL",
        "colab_type": "text"
      },
      "source": [
        "#### 2.3. Binarized Fully Connected Layer\n",
        "\n",
        "Binarization을 사용하여 딥러닝 네트워크를 만들기 위해서, 앞서 정의한 Binarize() 함수를 사용하는 Fully Connected Layer와 2-Dimension Convolutional Layer를 새롭게 정의하였다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3qibN8cOIqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BinarizeFullyConnected(nn.Linear):\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeFullyConnected, self).__init__(*kargs, **kwargs)\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        # Do binarization except first layer\n",
        "        if input.size(1) != 784:  # 28 x 28 = 784\n",
        "            input.data=Binarize(input.data)\n",
        "\n",
        "        # Make orginal attribute in Parameter to save the original weight\n",
        "        if not hasattr(self.weight,'orginal'):\n",
        "            self.weight.orginal=self.weight.data.clone()\n",
        "        self.weight.data=Binarize(self.weight.orginal)\n",
        "\n",
        "        # Do Linear operation with binarized weights\n",
        "        out = nn.functional.linear(input, self.weight)\n",
        "\n",
        "        # Add a bias to the result \n",
        "        if not self.bias is None:\n",
        "            self.bias.orginal=self.bias.data.clone()\n",
        "            out += self.bias.view(1, -1).expand_as(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSYmeKZNIq5r",
        "colab_type": "text"
      },
      "source": [
        "#### 2.4. Binarized Neural Network\n",
        "\n",
        "MNIST 데이터셋을 Training 하기 위한 네트워크를 구성하였다. 기본적으로 4개의 Fully Connected Layer를 나열하였으며, 각 레이어마다 Activation Function으로 HardTanh()를 사용하였다. 추가로 네트워크의 정확도를 위해 Batch Normalization을 적용하였다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U71z_RfhWdQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinaryNet(nn.Module):\n",
        "  def __init__(self, binary=True, factor = 1):\n",
        "    self.binarized = binary\n",
        "    # factor means scale factor to increase the size of network easily or dynamically\n",
        "    # Binarized fully connected configuration\n",
        "    if binary:\n",
        "      super(BinaryNet, self).__init__()\n",
        "      self.fc1 = BinarizeFullyConnected(28*28, 1024*factor)\n",
        "      self.fc2 = BinarizeFullyConnected(1024*factor, 1024*factor)\n",
        "      self.fc3 = BinarizeFullyConnected(1024*factor, 1024*factor)\n",
        "      self.fc4 = BinarizeFullyConnected(1024*factor, 10)\n",
        "    # Normal Fully connected configuration\n",
        "    else:\n",
        "      super(BinaryNet, self).__init__()\n",
        "      self.fc1 = nn.Linear(28*28, 1024*factor)\n",
        "      self.fc2 = nn.Linear(1024*factor, 1024*factor)\n",
        "      self.fc3 = nn.Linear(1024*factor, 1024*factor)\n",
        "      self.fc4 = nn.Linear(1024*factor, 10)\n",
        "      \n",
        "    # Set other layers (activation, batch normalization, softmax)\n",
        "    self.htanh1 = nn.Hardtanh()               # Activate function with HardTanh in PyTorch Library. Default min and max are -1 and 1.\n",
        "    self.bn1 = nn.BatchNorm1d(1024*factor)\n",
        "    self.htanh2 = nn.Hardtanh()\n",
        "    self.bn2 = nn.BatchNorm1d(1024*factor)\n",
        "    self.htanh3 = nn.Hardtanh()\n",
        "    self.bn3 = nn.BatchNorm1d(1024*factor)\n",
        "    self.logsoftmax=nn.LogSoftmax()\n",
        "\n",
        "  # Configuration for forward propagation\n",
        "  def forward(self, input):\n",
        "    x = input.view(-1, 28*28)\n",
        "    x = self.fc1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.htanh1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.htanh2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.bn3(x)\n",
        "    x = self.htanh3(x)\n",
        "    x = self.fc4(x) \n",
        "    x = self.logsoftmax(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k8ET18SSODO",
        "colab_type": "text"
      },
      "source": [
        "#### 2.5. Training Code\n",
        "Training 과정을 정의하기 위한 부분이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmJtB7exHfkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "def train(model, optimizer, criterion, epoch):\n",
        "  model.train()\n",
        "  # train each mini batches\n",
        "  for idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = Variable(data.to(device)), Variable(target.to(device))\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    if epoch % 40 == 0:\n",
        "      optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] * 0.1\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for p in list(model.parameters()):\n",
        "      if hasattr(p,'orginal'):\n",
        "        p.data.copy_(p.orginal)\n",
        "    optimizer.step()\n",
        "\n",
        "    for p in list(model.parameters()):\n",
        "      if hasattr(p,'orginal'):\n",
        "        p.orginal.copy_(p.data.clamp_(-1,1))\n",
        "    \n",
        "    if idx % log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.item()))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZOjREiTSgaU",
        "colab_type": "text"
      },
      "source": [
        "#### 2.6. Testing Code\n",
        "Testing 과정을 정의하기 위한 부분이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnSzikRwHh_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_state(model, acc):\n",
        "    print('==> Saving model ...')\n",
        "    state = {\n",
        "            'acc': acc,\n",
        "            'state_dict': model.state_dict(),\n",
        "            }\n",
        "    for key in state['state_dict'].keys():\n",
        "        if 'module' in key:\n",
        "            state['state_dict'][key.replace('module.', '')] = \\\n",
        "                    state['state_dict'].pop(key)\n",
        "    # torch.save(state, 'models/'+args.arch+'.best.pth.tar')\n",
        "    if model.binarized:\n",
        "      model_name = \"binary_\"\n",
        "    else:\n",
        "      model_name = \"normal_\"\n",
        "    torch.save(state, model_name+'best.pth.tar')\n",
        "\n",
        "def test(model, criterion):\n",
        "  global best_acc\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = Variable(data.to(device)), Variable(target.to(device))\n",
        "      output = model(data)\n",
        "      test_loss += criterion(output, target).item()   # sum up batch loss\n",
        "      pred = output.data.max(1, keepdim=True)[1]      # get the index of the max log-probability\n",
        "      correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "  \n",
        "    acc = 100. * float(correct) / len(test_loader.dataset)\n",
        "    if (acc > best_acc):\n",
        "        best_acc = acc\n",
        "        # if not evaluate:\n",
        "        save_state(model, best_acc)\n",
        "  \n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), 100. *correct / len(test_loader.dataset)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDQV-L8VSl-t",
        "colab_type": "text"
      },
      "source": [
        "#### 2.7. Configuration and Datasets\n",
        "\n",
        "MNIST Training을 위해 MNIST 데이터셋을 다운로드하고, 디바이스 설정과 Training에 필요한 factor를 설정한다.\n",
        "\n",
        "Loss Funciton으로는 Cross Entropy Function 을 사용하였고, Optimizer로는 Adam을 사용하였다.\n",
        "\n",
        "|Name|Factor|\n",
        "|:---:|:---:|\n",
        "|Optimizer|__Adam__|\n",
        "|Loss Funciton|__Cross Entropy__|\n",
        "|epoch|100|\n",
        "|batch size|64|\n",
        "|learning rate|0.0001|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkootFQGPnSc",
        "colab_type": "code",
        "outputId": "708c3d25-ef33-42d6-96e7-72211be78b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "seed = 1                  # Parameter for Random Generator in PyTorch\n",
        "epochs = 100              # Number of epochs\n",
        "batch_size = 64           # Size of the batch in each training\n",
        "test_batch_size = 1000    # Size of the batch in each test\n",
        "lr = 1e-4                 # Learning Rate\n",
        "interval = 10             # Term for printing the result of the training at each epoch\n",
        "best_acc = 0.0            # Variable to save the highest accuracy\n",
        "save_model = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()  # use Cuda\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"Computing Environment: \", device)\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "transform=transforms.Compose([\n",
        "   transforms.ToTensor(),\n",
        "   transforms.Normalize((0.1307,), (0.3081,)) ])\n",
        "\n",
        "\n",
        "# MNIST dataset loading\n",
        "torch.manual_seed(seed)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('drive/My Drive/{8th Semester}/Machine Learning/hw/hw7/', train=True, \n",
        "                   download=True, transform=transform),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('drive/My Drive/{8th Semester}/Machine Learning/hw/hw7/', train=False, \n",
        "                   transform=transform),\n",
        "    batch_size=test_batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "# make interval to print training processes and losses\n",
        "log_interval = len(train_loader.dataset) / batch_size / interval\n",
        "\n",
        "# scale factor of the linear layer\n",
        "factor = 2\n",
        "\n",
        "# make models, criterion, and optimizer\n",
        "binarized_model = BinaryNet(binary=True, factor = factor).to(device)  # make binarized model \n",
        "normal_model = BinaryNet(binary=False, factor = factor).to(device)    # make normal model \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "b_optimizer = optim.Adam(binarized_model.parameters(), lr=lr)\n",
        "n_optimizer = optim.Adam(normal_model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing Environment:  cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g-0DJ_7UUNu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 3\\. Result(Comparing Accuracy)\n",
        "#### 3.1. Training and Testing MNIST Datasets on Binarized Neural Network \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbj7wFVDHkwP",
        "colab_type": "code",
        "outputId": "e5c511ac-3587-455d-e74b-e03480ba12aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train and test on binarized model \n",
        "for epoch in range(1, epochs + 1):\n",
        "  train(binarized_model, b_optimizer, criterion, epoch)\n",
        "  test(binarized_model, criterion)\n",
        "  if epoch % 40 == 0:\n",
        "    b_optimizer.param_groups[0]['lr'] = b_optimizer.param_groups[0]['lr']*0.1\n",
        "\n",
        "\n",
        "binary_best = best_acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 79.009827\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 9.532460\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 6.324212\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0049, Accuracy: 9184/10000 (91.84%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 4.093976\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 3.844896\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 5.748398\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0033, Accuracy: 9415/10000 (94.15%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.343578\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 2.698038\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 3.001101\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0036, Accuracy: 9437/10000 (94.37%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.905661\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 3.623110\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.010904\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0031, Accuracy: 9497/10000 (94.97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.687773\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 2.124351\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 7.467796\n",
            "\n",
            "Test set: Average Loss: 0.0037, Accuracy: 9466/10000 (94.66%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.438046\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 2.284315\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0033, Accuracy: 9554/10000 (95.54%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.281464\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 1.968236\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 4.219265\n",
            "\n",
            "Test set: Average Loss: 0.0039, Accuracy: 9517/10000 (95.17%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.688090\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.625943\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0030, Accuracy: 9619/10000 (96.19%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.406601\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.000292\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.312881\n",
            "\n",
            "Test set: Average Loss: 0.0032, Accuracy: 9591/10000 (95.91%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.126144\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 3.812124\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 4.250806\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9659/10000 (96.59%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.156126\n",
            "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0024, Accuracy: 9680/10000 (96.80%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000291\n",
            "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.188247\n",
            "\n",
            "Test set: Average Loss: 0.0032, Accuracy: 9650/10000 (96.50%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 2.064138\n",
            "Train Epoch: 13 [24000/60000 (40%)]\tLoss: 3.261493\n",
            "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.032860\n",
            "\n",
            "Test set: Average Loss: 0.0034, Accuracy: 9631/10000 (96.31%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 3.031672\n",
            "Train Epoch: 14 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.033666\n",
            "\n",
            "Test set: Average Loss: 0.0032, Accuracy: 9641/10000 (96.41%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 5.561969\n",
            "Train Epoch: 15 [24000/60000 (40%)]\tLoss: 3.405807\n",
            "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 3.688288\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9674/10000 (96.74%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 16 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.405738\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9691/10000 (96.91%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 2.530789\n",
            "Train Epoch: 17 [24000/60000 (40%)]\tLoss: 1.030846\n",
            "Train Epoch: 17 [48000/60000 (80%)]\tLoss: 0.000005\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9681/10000 (96.81%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [24000/60000 (40%)]\tLoss: 0.437019\n",
            "Train Epoch: 18 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9714/10000 (97.14%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.405526\n",
            "Train Epoch: 19 [24000/60000 (40%)]\tLoss: 0.343608\n",
            "Train Epoch: 19 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9707/10000 (97.07%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [24000/60000 (40%)]\tLoss: 0.875910\n",
            "Train Epoch: 20 [48000/60000 (80%)]\tLoss: 1.030970\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9726/10000 (97.26%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [24000/60000 (40%)]\tLoss: 6.220167\n",
            "Train Epoch: 21 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0030, Accuracy: 9702/10000 (97.02%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [24000/60000 (40%)]\tLoss: 0.218005\n",
            "Train Epoch: 22 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0031, Accuracy: 9692/10000 (96.92%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000001\n",
            "Train Epoch: 23 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9722/10000 (97.22%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [24000/60000 (40%)]\tLoss: 0.374714\n",
            "Train Epoch: 24 [48000/60000 (80%)]\tLoss: 0.998718\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0023, Accuracy: 9764/10000 (97.64%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [24000/60000 (40%)]\tLoss: 3.124828\n",
            "Train Epoch: 25 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0032, Accuracy: 9704/10000 (97.04%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [24000/60000 (40%)]\tLoss: 0.375009\n",
            "Train Epoch: 26 [48000/60000 (80%)]\tLoss: 1.311686\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9712/10000 (97.12%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9732/10000 (97.32%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.500929\n",
            "Train Epoch: 28 [24000/60000 (40%)]\tLoss: 1.124397\n",
            "Train Epoch: 28 [48000/60000 (80%)]\tLoss: 0.187475\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0023, Accuracy: 9770/10000 (97.70%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.749090\n",
            "Train Epoch: 29 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0030, Accuracy: 9701/10000 (97.01%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.010684\n",
            "Train Epoch: 30 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [48000/60000 (80%)]\tLoss: 0.093682\n",
            "\n",
            "Test set: Average Loss: 0.0034, Accuracy: 9694/10000 (96.94%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 1.125320\n",
            "Train Epoch: 31 [24000/60000 (40%)]\tLoss: 0.469294\n",
            "Train Epoch: 31 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0030, Accuracy: 9746/10000 (97.46%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.063422\n",
            "Train Epoch: 32 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 32 [48000/60000 (80%)]\tLoss: 0.094424\n",
            "\n",
            "Test set: Average Loss: 0.0026, Accuracy: 9724/10000 (97.24%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 1.438648\n",
            "Train Epoch: 33 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 33 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0024, Accuracy: 9761/10000 (97.61%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.001872\n",
            "Train Epoch: 34 [24000/60000 (40%)]\tLoss: 0.010657\n",
            "Train Epoch: 34 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0026, Accuracy: 9746/10000 (97.46%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 2.812652\n",
            "Train Epoch: 35 [24000/60000 (40%)]\tLoss: 3.189077\n",
            "Train Epoch: 35 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9734/10000 (97.34%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.970655\n",
            "Train Epoch: 36 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 36 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9751/10000 (97.51%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.657105\n",
            "Train Epoch: 37 [24000/60000 (40%)]\tLoss: 0.000038\n",
            "Train Epoch: 37 [48000/60000 (80%)]\tLoss: 1.342334\n",
            "\n",
            "Test set: Average Loss: 0.0030, Accuracy: 9730/10000 (97.30%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 38 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 38 [48000/60000 (80%)]\tLoss: 0.281298\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9768/10000 (97.68%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 39 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 39 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9762/10000 (97.62%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 40 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 40 [48000/60000 (80%)]\tLoss: 0.718709\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9746/10000 (97.46%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 41 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 41 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9753/10000 (97.53%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 2.000226\n",
            "Train Epoch: 42 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 42 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9750/10000 (97.50%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 43 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 43 [48000/60000 (80%)]\tLoss: 0.468863\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9753/10000 (97.53%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.063343\n",
            "Train Epoch: 44 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 44 [48000/60000 (80%)]\tLoss: 0.001866\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9756/10000 (97.56%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000001\n",
            "Train Epoch: 45 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 45 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9759/10000 (97.59%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 46 [24000/60000 (40%)]\tLoss: 0.000298\n",
            "Train Epoch: 46 [48000/60000 (80%)]\tLoss: 0.575267\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9757/10000 (97.57%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 47 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 47 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9748/10000 (97.48%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.311736\n",
            "Train Epoch: 48 [24000/60000 (40%)]\tLoss: 0.375637\n",
            "Train Epoch: 48 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9752/10000 (97.52%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 49 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 49 [48000/60000 (80%)]\tLoss: 0.093901\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9762/10000 (97.62%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.906209\n",
            "Train Epoch: 50 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 50 [48000/60000 (80%)]\tLoss: 0.468620\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9753/10000 (97.53%)\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 51 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 51 [48000/60000 (80%)]\tLoss: 1.843709\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9754/10000 (97.54%)\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 2.758988\n",
            "Train Epoch: 52 [24000/60000 (40%)]\tLoss: 0.002025\n",
            "Train Epoch: 52 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9753/10000 (97.53%)\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.033333\n",
            "Train Epoch: 53 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 53 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9751/10000 (97.51%)\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.010864\n",
            "Train Epoch: 54 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 54 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9747/10000 (97.47%)\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.280906\n",
            "Train Epoch: 55 [24000/60000 (40%)]\tLoss: 1.312572\n",
            "Train Epoch: 55 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9744/10000 (97.44%)\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 56 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 56 [48000/60000 (80%)]\tLoss: 0.128401\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9749/10000 (97.49%)\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 57 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 57 [48000/60000 (80%)]\tLoss: 0.033134\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9751/10000 (97.51%)\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 3.936782\n",
            "Train Epoch: 58 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 58 [48000/60000 (80%)]\tLoss: 0.188070\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9751/10000 (97.51%)\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 59 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 59 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9744/10000 (97.44%)\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.343200\n",
            "Train Epoch: 60 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 60 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9753/10000 (97.53%)\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.000001\n",
            "Train Epoch: 61 [24000/60000 (40%)]\tLoss: 0.656137\n",
            "Train Epoch: 61 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9756/10000 (97.56%)\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 62 [24000/60000 (40%)]\tLoss: 0.156138\n",
            "Train Epoch: 62 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9755/10000 (97.55%)\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 63 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 63 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9750/10000 (97.50%)\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 64 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 64 [48000/60000 (80%)]\tLoss: 0.219299\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9738/10000 (97.38%)\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 65 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 65 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9741/10000 (97.41%)\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 66 [24000/60000 (40%)]\tLoss: 1.594278\n",
            "Train Epoch: 66 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9745/10000 (97.45%)\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 67 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 67 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9752/10000 (97.52%)\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 68 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 68 [48000/60000 (80%)]\tLoss: 0.002350\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9748/10000 (97.48%)\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.156209\n",
            "Train Epoch: 69 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 69 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9762/10000 (97.62%)\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.000005\n",
            "Train Epoch: 70 [24000/60000 (40%)]\tLoss: 1.156209\n",
            "Train Epoch: 70 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9751/10000 (97.51%)\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.033197\n",
            "Train Epoch: 71 [24000/60000 (40%)]\tLoss: 0.656799\n",
            "Train Epoch: 71 [48000/60000 (80%)]\tLoss: 1.155235\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9743/10000 (97.43%)\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 72 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 72 [48000/60000 (80%)]\tLoss: 1.812777\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9749/10000 (97.49%)\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 73 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 73 [48000/60000 (80%)]\tLoss: 0.748410\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9743/10000 (97.43%)\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.686480\n",
            "Train Epoch: 74 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 74 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9749/10000 (97.49%)\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.219349\n",
            "Train Epoch: 75 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 75 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9758/10000 (97.58%)\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.000040\n",
            "Train Epoch: 76 [24000/60000 (40%)]\tLoss: 0.011158\n",
            "Train Epoch: 76 [48000/60000 (80%)]\tLoss: 0.000040\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9757/10000 (97.57%)\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 77 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 77 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9769/10000 (97.69%)\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 78 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 78 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9749/10000 (97.49%)\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 79 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 79 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9753/10000 (97.53%)\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 1.280846\n",
            "Train Epoch: 80 [24000/60000 (40%)]\tLoss: 1.688393\n",
            "Train Epoch: 80 [48000/60000 (80%)]\tLoss: 2.344754\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9746/10000 (97.46%)\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 81 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 81 [48000/60000 (80%)]\tLoss: 1.346144\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9755/10000 (97.55%)\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 82 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 82 [48000/60000 (80%)]\tLoss: 3.372077\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9758/10000 (97.58%)\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 83 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 83 [48000/60000 (80%)]\tLoss: 1.781594\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9744/10000 (97.44%)\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 84 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 84 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9742/10000 (97.42%)\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 85 [24000/60000 (40%)]\tLoss: 0.063534\n",
            "Train Epoch: 85 [48000/60000 (80%)]\tLoss: 1.438648\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9750/10000 (97.50%)\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.000001\n",
            "Train Epoch: 86 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 86 [48000/60000 (80%)]\tLoss: 2.876745\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9742/10000 (97.42%)\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 87 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 87 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9749/10000 (97.49%)\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.280574\n",
            "Train Epoch: 88 [24000/60000 (40%)]\tLoss: 0.156209\n",
            "Train Epoch: 88 [48000/60000 (80%)]\tLoss: 0.469299\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9744/10000 (97.44%)\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 89 [24000/60000 (40%)]\tLoss: 1.217504\n",
            "Train Epoch: 89 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9753/10000 (97.53%)\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 90 [24000/60000 (40%)]\tLoss: 0.717504\n",
            "Train Epoch: 90 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9749/10000 (97.49%)\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.001978\n",
            "Train Epoch: 91 [24000/60000 (40%)]\tLoss: 0.311385\n",
            "Train Epoch: 91 [48000/60000 (80%)]\tLoss: 0.011217\n",
            "\n",
            "Test set: Average Loss: 0.0029, Accuracy: 9759/10000 (97.59%)\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 92 [24000/60000 (40%)]\tLoss: 1.281137\n",
            "Train Epoch: 92 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9759/10000 (97.59%)\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 93 [24000/60000 (40%)]\tLoss: 0.000005\n",
            "Train Epoch: 93 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9754/10000 (97.54%)\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 1.311280\n",
            "Train Epoch: 94 [24000/60000 (40%)]\tLoss: 0.312777\n",
            "Train Epoch: 94 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9756/10000 (97.56%)\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.000001\n",
            "Train Epoch: 95 [24000/60000 (40%)]\tLoss: 1.280574\n",
            "Train Epoch: 95 [48000/60000 (80%)]\tLoss: 0.468709\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9753/10000 (97.53%)\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.010453\n",
            "Train Epoch: 96 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 96 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9752/10000 (97.52%)\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 97 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 97 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9752/10000 (97.52%)\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.187731\n",
            "Train Epoch: 98 [24000/60000 (40%)]\tLoss: 0.812417\n",
            "Train Epoch: 98 [48000/60000 (80%)]\tLoss: 1.696086\n",
            "\n",
            "Test set: Average Loss: 0.0027, Accuracy: 9756/10000 (97.56%)\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.219094\n",
            "Train Epoch: 99 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 99 [48000/60000 (80%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9748/10000 (97.48%)\n",
            "\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 100 [24000/60000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 100 [48000/60000 (80%)]\tLoss: 0.032639\n",
            "\n",
            "Test set: Average Loss: 0.0028, Accuracy: 9743/10000 (97.43%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZwdJJKPU5Fl",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2. Training and Testing on Deep Neural Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV_7v5slJylN",
        "colab_type": "code",
        "outputId": "e8cd2e12-cf76-478c-915b-d472091ff356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train and test on Normal model \n",
        "for epoch in range(1, epochs + 1):\n",
        "  train(normal_model, n_optimizer, criterion, epoch)\n",
        "  test(normal_model, criterion)\n",
        "  if epoch % 40 == 0:\n",
        "    n_optimizer.param_groups[0]['lr'] = n_optimizer.param_groups[0]['lr']*0.1\n",
        "\n",
        "normal_best = best_acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.483741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.283368\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.263458\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.483741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.283368\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.263458\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9613/10000 (96.13%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9613/10000 (96.13%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.043968\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.043968\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.037649\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.037649\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.097217\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.097217\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9712/10000 (97.12%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9712/10000 (97.12%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.028836\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.028836\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.044312\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.044312\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.132647\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.132647\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9702/10000 (97.02%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9702/10000 (97.02%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.120106\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.120106\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.015781\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.015781\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.053558\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.053558\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9706/10000 (97.06%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9706/10000 (97.06%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.067284\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.067284\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.002576\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.002576\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.070121\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.070121\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9741/10000 (97.41%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9741/10000 (97.41%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.010904\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.010904\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.005281\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.005281\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.121006\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.121006\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9771/10000 (97.71%)\n",
            "\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9771/10000 (97.71%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.009185\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.009185\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.027708\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.027708\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.003845\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.003845\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9754/10000 (97.54%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9754/10000 (97.54%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.033778\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.033778\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.019567\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.019567\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.036399\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.036399\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9765/10000 (97.65%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9765/10000 (97.65%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.035136\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.035136\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.005583\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.005583\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.020303\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.020303\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9766/10000 (97.66%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9766/10000 (97.66%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000924\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000924\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.048692\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.048692\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.001572\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.001572\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9758/10000 (97.58%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9758/10000 (97.58%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.037990\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.037990\n",
            "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.002829\n",
            "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.002829\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.002222\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.002222\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.006052\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.006052\n",
            "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.005721\n",
            "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.005721\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.012869\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.012869\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.010628\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.010628\n",
            "Train Epoch: 13 [24000/60000 (40%)]\tLoss: 0.006111\n",
            "Train Epoch: 13 [24000/60000 (40%)]\tLoss: 0.006111\n",
            "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.012585\n",
            "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.012585\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9752/10000 (97.52%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9752/10000 (97.52%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.022977\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.022977\n",
            "Train Epoch: 14 [24000/60000 (40%)]\tLoss: 0.001523\n",
            "Train Epoch: 14 [24000/60000 (40%)]\tLoss: 0.001523\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.009834\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.009834\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.006126\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.006126\n",
            "Train Epoch: 15 [24000/60000 (40%)]\tLoss: 0.063089\n",
            "Train Epoch: 15 [24000/60000 (40%)]\tLoss: 0.063089\n",
            "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.039844\n",
            "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.039844\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9790/10000 (97.90%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9790/10000 (97.90%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.002322\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.002322\n",
            "Train Epoch: 16 [24000/60000 (40%)]\tLoss: 0.022705\n",
            "Train Epoch: 16 [24000/60000 (40%)]\tLoss: 0.022705\n",
            "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.010164\n",
            "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.010164\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9766/10000 (97.66%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9766/10000 (97.66%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.007093\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.007093\n",
            "Train Epoch: 17 [24000/60000 (40%)]\tLoss: 0.008294\n",
            "Train Epoch: 17 [24000/60000 (40%)]\tLoss: 0.008294\n",
            "Train Epoch: 17 [48000/60000 (80%)]\tLoss: 0.081404\n",
            "Train Epoch: 17 [48000/60000 (80%)]\tLoss: 0.081404\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000885\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000885\n",
            "Train Epoch: 18 [24000/60000 (40%)]\tLoss: 0.000333\n",
            "Train Epoch: 18 [24000/60000 (40%)]\tLoss: 0.000333\n",
            "Train Epoch: 18 [48000/60000 (80%)]\tLoss: 0.002186\n",
            "Train Epoch: 18 [48000/60000 (80%)]\tLoss: 0.002186\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.002339\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.002339\n",
            "Train Epoch: 19 [24000/60000 (40%)]\tLoss: 0.002733\n",
            "Train Epoch: 19 [24000/60000 (40%)]\tLoss: 0.002733\n",
            "Train Epoch: 19 [48000/60000 (80%)]\tLoss: 0.065198\n",
            "Train Epoch: 19 [48000/60000 (80%)]\tLoss: 0.065198\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9741/10000 (97.41%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9741/10000 (97.41%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.007057\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.007057\n",
            "Train Epoch: 20 [24000/60000 (40%)]\tLoss: 0.000077\n",
            "Train Epoch: 20 [24000/60000 (40%)]\tLoss: 0.000077\n",
            "Train Epoch: 20 [48000/60000 (80%)]\tLoss: 0.041103\n",
            "Train Epoch: 20 [48000/60000 (80%)]\tLoss: 0.041103\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9731/10000 (97.31%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9731/10000 (97.31%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.007863\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.007863\n",
            "Train Epoch: 21 [24000/60000 (40%)]\tLoss: 0.000991\n",
            "Train Epoch: 21 [24000/60000 (40%)]\tLoss: 0.000991\n",
            "Train Epoch: 21 [48000/60000 (80%)]\tLoss: 0.011238\n",
            "Train Epoch: 21 [48000/60000 (80%)]\tLoss: 0.011238\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9784/10000 (97.84%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9784/10000 (97.84%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.004664\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.004664\n",
            "Train Epoch: 22 [24000/60000 (40%)]\tLoss: 0.008309\n",
            "Train Epoch: 22 [24000/60000 (40%)]\tLoss: 0.008309\n",
            "Train Epoch: 22 [48000/60000 (80%)]\tLoss: 0.000627\n",
            "Train Epoch: 22 [48000/60000 (80%)]\tLoss: 0.000627\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9792/10000 (97.92%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9792/10000 (97.92%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.025038\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.025038\n",
            "Train Epoch: 23 [24000/60000 (40%)]\tLoss: 0.000197\n",
            "Train Epoch: 23 [24000/60000 (40%)]\tLoss: 0.000197\n",
            "Train Epoch: 23 [48000/60000 (80%)]\tLoss: 0.003966\n",
            "Train Epoch: 23 [48000/60000 (80%)]\tLoss: 0.003966\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.003272\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.003272\n",
            "Train Epoch: 24 [24000/60000 (40%)]\tLoss: 0.007263\n",
            "Train Epoch: 24 [24000/60000 (40%)]\tLoss: 0.007263\n",
            "Train Epoch: 24 [48000/60000 (80%)]\tLoss: 0.000575\n",
            "Train Epoch: 24 [48000/60000 (80%)]\tLoss: 0.000575\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.034340\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.034340\n",
            "Train Epoch: 25 [24000/60000 (40%)]\tLoss: 0.002935\n",
            "Train Epoch: 25 [24000/60000 (40%)]\tLoss: 0.002935\n",
            "Train Epoch: 25 [48000/60000 (80%)]\tLoss: 0.004416\n",
            "Train Epoch: 25 [48000/60000 (80%)]\tLoss: 0.004416\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.003563\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.003563\n",
            "Train Epoch: 26 [24000/60000 (40%)]\tLoss: 0.002003\n",
            "Train Epoch: 26 [24000/60000 (40%)]\tLoss: 0.002003\n",
            "Train Epoch: 26 [48000/60000 (80%)]\tLoss: 0.000900\n",
            "Train Epoch: 26 [48000/60000 (80%)]\tLoss: 0.000900\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.064614\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.064614\n",
            "Train Epoch: 27 [24000/60000 (40%)]\tLoss: 0.000557\n",
            "Train Epoch: 27 [24000/60000 (40%)]\tLoss: 0.000557\n",
            "Train Epoch: 27 [48000/60000 (80%)]\tLoss: 0.009898\n",
            "Train Epoch: 27 [48000/60000 (80%)]\tLoss: 0.009898\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000102\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000102\n",
            "Train Epoch: 28 [24000/60000 (40%)]\tLoss: 0.000077\n",
            "Train Epoch: 28 [24000/60000 (40%)]\tLoss: 0.000077\n",
            "Train Epoch: 28 [48000/60000 (80%)]\tLoss: 0.004065\n",
            "Train Epoch: 28 [48000/60000 (80%)]\tLoss: 0.004065\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000093\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000093\n",
            "Train Epoch: 29 [24000/60000 (40%)]\tLoss: 0.000457\n",
            "Train Epoch: 29 [24000/60000 (40%)]\tLoss: 0.000457\n",
            "Train Epoch: 29 [48000/60000 (80%)]\tLoss: 0.000264\n",
            "Train Epoch: 29 [48000/60000 (80%)]\tLoss: 0.000264\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9806/10000 (98.06%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9806/10000 (98.06%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.001003\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.001003\n",
            "Train Epoch: 30 [24000/60000 (40%)]\tLoss: 0.001540\n",
            "Train Epoch: 30 [24000/60000 (40%)]\tLoss: 0.001540\n",
            "Train Epoch: 30 [48000/60000 (80%)]\tLoss: 0.002219\n",
            "Train Epoch: 30 [48000/60000 (80%)]\tLoss: 0.002219\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9794/10000 (97.94%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9794/10000 (97.94%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.001980\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.001980\n",
            "Train Epoch: 31 [24000/60000 (40%)]\tLoss: 0.000518\n",
            "Train Epoch: 31 [24000/60000 (40%)]\tLoss: 0.000518\n",
            "Train Epoch: 31 [48000/60000 (80%)]\tLoss: 0.016354\n",
            "Train Epoch: 31 [48000/60000 (80%)]\tLoss: 0.016354\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9768/10000 (97.68%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9768/10000 (97.68%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000461\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000461\n",
            "Train Epoch: 32 [24000/60000 (40%)]\tLoss: 0.008342\n",
            "Train Epoch: 32 [24000/60000 (40%)]\tLoss: 0.008342\n",
            "Train Epoch: 32 [48000/60000 (80%)]\tLoss: 0.006437\n",
            "Train Epoch: 32 [48000/60000 (80%)]\tLoss: 0.006437\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9788/10000 (97.88%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9788/10000 (97.88%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000342\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000342\n",
            "Train Epoch: 33 [24000/60000 (40%)]\tLoss: 0.000278\n",
            "Train Epoch: 33 [24000/60000 (40%)]\tLoss: 0.000278\n",
            "Train Epoch: 33 [48000/60000 (80%)]\tLoss: 0.000943\n",
            "Train Epoch: 33 [48000/60000 (80%)]\tLoss: 0.000943\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.002798\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.002798\n",
            "Train Epoch: 34 [24000/60000 (40%)]\tLoss: 0.003902\n",
            "Train Epoch: 34 [24000/60000 (40%)]\tLoss: 0.003902\n",
            "Train Epoch: 34 [48000/60000 (80%)]\tLoss: 0.000227\n",
            "Train Epoch: 34 [48000/60000 (80%)]\tLoss: 0.000227\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.001106\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.001106\n",
            "Train Epoch: 35 [24000/60000 (40%)]\tLoss: 0.001855\n",
            "Train Epoch: 35 [24000/60000 (40%)]\tLoss: 0.001855\n",
            "Train Epoch: 35 [48000/60000 (80%)]\tLoss: 0.024814\n",
            "Train Epoch: 35 [48000/60000 (80%)]\tLoss: 0.024814\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000183\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000183\n",
            "Train Epoch: 36 [24000/60000 (40%)]\tLoss: 0.049626\n",
            "Train Epoch: 36 [24000/60000 (40%)]\tLoss: 0.049626\n",
            "Train Epoch: 36 [48000/60000 (80%)]\tLoss: 0.000284\n",
            "Train Epoch: 36 [48000/60000 (80%)]\tLoss: 0.000284\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9817/10000 (98.17%)\n",
            "\n",
            "==> Saving model ...\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9817/10000 (98.17%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000094\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000094\n",
            "Train Epoch: 37 [24000/60000 (40%)]\tLoss: 0.002244\n",
            "Train Epoch: 37 [24000/60000 (40%)]\tLoss: 0.002244\n",
            "Train Epoch: 37 [48000/60000 (80%)]\tLoss: 0.000160\n",
            "Train Epoch: 37 [48000/60000 (80%)]\tLoss: 0.000160\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.000646\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.000646\n",
            "Train Epoch: 38 [24000/60000 (40%)]\tLoss: 0.026713\n",
            "Train Epoch: 38 [24000/60000 (40%)]\tLoss: 0.026713\n",
            "Train Epoch: 38 [48000/60000 (80%)]\tLoss: 0.001592\n",
            "Train Epoch: 38 [48000/60000 (80%)]\tLoss: 0.001592\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.003806\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.003806\n",
            "Train Epoch: 39 [24000/60000 (40%)]\tLoss: 0.001870\n",
            "Train Epoch: 39 [24000/60000 (40%)]\tLoss: 0.001870\n",
            "Train Epoch: 39 [48000/60000 (80%)]\tLoss: 0.002189\n",
            "Train Epoch: 39 [48000/60000 (80%)]\tLoss: 0.002189\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.003423\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.003423\n",
            "Train Epoch: 40 [24000/60000 (40%)]\tLoss: 0.001010\n",
            "Train Epoch: 40 [24000/60000 (40%)]\tLoss: 0.001010\n",
            "Train Epoch: 40 [48000/60000 (80%)]\tLoss: 0.001774\n",
            "Train Epoch: 40 [48000/60000 (80%)]\tLoss: 0.001774\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000100\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000100\n",
            "Train Epoch: 41 [24000/60000 (40%)]\tLoss: 0.000353\n",
            "Train Epoch: 41 [24000/60000 (40%)]\tLoss: 0.000353\n",
            "Train Epoch: 41 [48000/60000 (80%)]\tLoss: 0.001106\n",
            "Train Epoch: 41 [48000/60000 (80%)]\tLoss: 0.001106\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9795/10000 (97.95%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9795/10000 (97.95%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000377\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000377\n",
            "Train Epoch: 42 [24000/60000 (40%)]\tLoss: 0.001883\n",
            "Train Epoch: 42 [24000/60000 (40%)]\tLoss: 0.001883\n",
            "Train Epoch: 42 [48000/60000 (80%)]\tLoss: 0.000283\n",
            "Train Epoch: 42 [48000/60000 (80%)]\tLoss: 0.000283\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.001290\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.001290\n",
            "Train Epoch: 43 [24000/60000 (40%)]\tLoss: 0.125192\n",
            "Train Epoch: 43 [24000/60000 (40%)]\tLoss: 0.125192\n",
            "Train Epoch: 43 [48000/60000 (80%)]\tLoss: 0.000057\n",
            "Train Epoch: 43 [48000/60000 (80%)]\tLoss: 0.000057\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.000039\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.000039\n",
            "Train Epoch: 44 [24000/60000 (40%)]\tLoss: 0.005593\n",
            "Train Epoch: 44 [24000/60000 (40%)]\tLoss: 0.005593\n",
            "Train Epoch: 44 [48000/60000 (80%)]\tLoss: 0.013753\n",
            "Train Epoch: 44 [48000/60000 (80%)]\tLoss: 0.013753\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000463\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000463\n",
            "Train Epoch: 45 [24000/60000 (40%)]\tLoss: 0.000585\n",
            "Train Epoch: 45 [24000/60000 (40%)]\tLoss: 0.000585\n",
            "Train Epoch: 45 [48000/60000 (80%)]\tLoss: 0.000046\n",
            "Train Epoch: 45 [48000/60000 (80%)]\tLoss: 0.000046\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9806/10000 (98.06%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9806/10000 (98.06%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000233\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000233\n",
            "Train Epoch: 46 [24000/60000 (40%)]\tLoss: 0.003385\n",
            "Train Epoch: 46 [24000/60000 (40%)]\tLoss: 0.003385\n",
            "Train Epoch: 46 [48000/60000 (80%)]\tLoss: 0.000028\n",
            "Train Epoch: 46 [48000/60000 (80%)]\tLoss: 0.000028\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000189\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000189\n",
            "Train Epoch: 47 [24000/60000 (40%)]\tLoss: 0.000650\n",
            "Train Epoch: 47 [24000/60000 (40%)]\tLoss: 0.000650\n",
            "Train Epoch: 47 [48000/60000 (80%)]\tLoss: 0.000328\n",
            "Train Epoch: 47 [48000/60000 (80%)]\tLoss: 0.000328\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000094\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000094\n",
            "Train Epoch: 48 [24000/60000 (40%)]\tLoss: 0.000032\n",
            "Train Epoch: 48 [24000/60000 (40%)]\tLoss: 0.000032\n",
            "Train Epoch: 48 [48000/60000 (80%)]\tLoss: 0.004736\n",
            "Train Epoch: 48 [48000/60000 (80%)]\tLoss: 0.004736\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9795/10000 (97.95%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9795/10000 (97.95%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000459\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000459\n",
            "Train Epoch: 49 [24000/60000 (40%)]\tLoss: 0.000926\n",
            "Train Epoch: 49 [24000/60000 (40%)]\tLoss: 0.000926\n",
            "Train Epoch: 49 [48000/60000 (80%)]\tLoss: 0.008000\n",
            "Train Epoch: 49 [48000/60000 (80%)]\tLoss: 0.008000\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000347\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000347\n",
            "Train Epoch: 50 [24000/60000 (40%)]\tLoss: 0.000267\n",
            "Train Epoch: 50 [24000/60000 (40%)]\tLoss: 0.000267\n",
            "Train Epoch: 50 [48000/60000 (80%)]\tLoss: 0.000334\n",
            "Train Epoch: 50 [48000/60000 (80%)]\tLoss: 0.000334\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.002761\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.002761\n",
            "Train Epoch: 51 [24000/60000 (40%)]\tLoss: 0.003905\n",
            "Train Epoch: 51 [24000/60000 (40%)]\tLoss: 0.003905\n",
            "Train Epoch: 51 [48000/60000 (80%)]\tLoss: 0.005667\n",
            "Train Epoch: 51 [48000/60000 (80%)]\tLoss: 0.005667\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.000817\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.000817\n",
            "Train Epoch: 52 [24000/60000 (40%)]\tLoss: 0.001622\n",
            "Train Epoch: 52 [24000/60000 (40%)]\tLoss: 0.001622\n",
            "Train Epoch: 52 [48000/60000 (80%)]\tLoss: 0.001049\n",
            "Train Epoch: 52 [48000/60000 (80%)]\tLoss: 0.001049\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.024172\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.024172\n",
            "Train Epoch: 53 [24000/60000 (40%)]\tLoss: 0.000176\n",
            "Train Epoch: 53 [24000/60000 (40%)]\tLoss: 0.000176\n",
            "Train Epoch: 53 [48000/60000 (80%)]\tLoss: 0.000082\n",
            "Train Epoch: 53 [48000/60000 (80%)]\tLoss: 0.000082\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.000615\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.000615\n",
            "Train Epoch: 54 [24000/60000 (40%)]\tLoss: 0.000119\n",
            "Train Epoch: 54 [24000/60000 (40%)]\tLoss: 0.000119\n",
            "Train Epoch: 54 [48000/60000 (80%)]\tLoss: 0.000398\n",
            "Train Epoch: 54 [48000/60000 (80%)]\tLoss: 0.000398\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9798/10000 (97.98%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9798/10000 (97.98%)\n",
            "\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.000337\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.000337\n",
            "Train Epoch: 55 [24000/60000 (40%)]\tLoss: 0.000149\n",
            "Train Epoch: 55 [24000/60000 (40%)]\tLoss: 0.000149\n",
            "Train Epoch: 55 [48000/60000 (80%)]\tLoss: 0.001006\n",
            "Train Epoch: 55 [48000/60000 (80%)]\tLoss: 0.001006\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.007939\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.007939\n",
            "Train Epoch: 56 [24000/60000 (40%)]\tLoss: 0.002200\n",
            "Train Epoch: 56 [24000/60000 (40%)]\tLoss: 0.002200\n",
            "Train Epoch: 56 [48000/60000 (80%)]\tLoss: 0.000389\n",
            "Train Epoch: 56 [48000/60000 (80%)]\tLoss: 0.000389\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000097\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000097\n",
            "Train Epoch: 57 [24000/60000 (40%)]\tLoss: 0.024960\n",
            "Train Epoch: 57 [24000/60000 (40%)]\tLoss: 0.024960\n",
            "Train Epoch: 57 [48000/60000 (80%)]\tLoss: 0.000403\n",
            "Train Epoch: 57 [48000/60000 (80%)]\tLoss: 0.000403\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.000574\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.000574\n",
            "Train Epoch: 58 [24000/60000 (40%)]\tLoss: 0.029572\n",
            "Train Epoch: 58 [24000/60000 (40%)]\tLoss: 0.029572\n",
            "Train Epoch: 58 [48000/60000 (80%)]\tLoss: 0.015156\n",
            "Train Epoch: 58 [48000/60000 (80%)]\tLoss: 0.015156\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.000299\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.000299\n",
            "Train Epoch: 59 [24000/60000 (40%)]\tLoss: 0.000315\n",
            "Train Epoch: 59 [24000/60000 (40%)]\tLoss: 0.000315\n",
            "Train Epoch: 59 [48000/60000 (80%)]\tLoss: 0.000902\n",
            "Train Epoch: 59 [48000/60000 (80%)]\tLoss: 0.000902\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.012503\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.012503\n",
            "Train Epoch: 60 [24000/60000 (40%)]\tLoss: 0.000091\n",
            "Train Epoch: 60 [24000/60000 (40%)]\tLoss: 0.000091\n",
            "Train Epoch: 60 [48000/60000 (80%)]\tLoss: 0.000128\n",
            "Train Epoch: 60 [48000/60000 (80%)]\tLoss: 0.000128\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.011090\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.011090\n",
            "Train Epoch: 61 [24000/60000 (40%)]\tLoss: 0.003884\n",
            "Train Epoch: 61 [24000/60000 (40%)]\tLoss: 0.003884\n",
            "Train Epoch: 61 [48000/60000 (80%)]\tLoss: 0.003911\n",
            "Train Epoch: 61 [48000/60000 (80%)]\tLoss: 0.003911\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.000413\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.000413\n",
            "Train Epoch: 62 [24000/60000 (40%)]\tLoss: 0.010007\n",
            "Train Epoch: 62 [24000/60000 (40%)]\tLoss: 0.010007\n",
            "Train Epoch: 62 [48000/60000 (80%)]\tLoss: 0.001994\n",
            "Train Epoch: 62 [48000/60000 (80%)]\tLoss: 0.001994\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.000295\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.000295\n",
            "Train Epoch: 63 [24000/60000 (40%)]\tLoss: 0.000150\n",
            "Train Epoch: 63 [24000/60000 (40%)]\tLoss: 0.000150\n",
            "Train Epoch: 63 [48000/60000 (80%)]\tLoss: 0.012900\n",
            "Train Epoch: 63 [48000/60000 (80%)]\tLoss: 0.012900\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.000365\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.000365\n",
            "Train Epoch: 64 [24000/60000 (40%)]\tLoss: 0.000646\n",
            "Train Epoch: 64 [24000/60000 (40%)]\tLoss: 0.000646\n",
            "Train Epoch: 64 [48000/60000 (80%)]\tLoss: 0.001102\n",
            "Train Epoch: 64 [48000/60000 (80%)]\tLoss: 0.001102\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.001964\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.001964\n",
            "Train Epoch: 65 [24000/60000 (40%)]\tLoss: 0.001038\n",
            "Train Epoch: 65 [24000/60000 (40%)]\tLoss: 0.001038\n",
            "Train Epoch: 65 [48000/60000 (80%)]\tLoss: 0.000030\n",
            "Train Epoch: 65 [48000/60000 (80%)]\tLoss: 0.000030\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.001316\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.001316\n",
            "Train Epoch: 66 [24000/60000 (40%)]\tLoss: 0.001134\n",
            "Train Epoch: 66 [24000/60000 (40%)]\tLoss: 0.001134\n",
            "Train Epoch: 66 [48000/60000 (80%)]\tLoss: 0.002842\n",
            "Train Epoch: 66 [48000/60000 (80%)]\tLoss: 0.002842\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.000281\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.000281\n",
            "Train Epoch: 67 [24000/60000 (40%)]\tLoss: 0.000040\n",
            "Train Epoch: 67 [24000/60000 (40%)]\tLoss: 0.000040\n",
            "Train Epoch: 67 [48000/60000 (80%)]\tLoss: 0.003497\n",
            "Train Epoch: 67 [48000/60000 (80%)]\tLoss: 0.003497\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000288\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000288\n",
            "Train Epoch: 68 [24000/60000 (40%)]\tLoss: 0.002908\n",
            "Train Epoch: 68 [24000/60000 (40%)]\tLoss: 0.002908\n",
            "Train Epoch: 68 [48000/60000 (80%)]\tLoss: 0.000201\n",
            "Train Epoch: 68 [48000/60000 (80%)]\tLoss: 0.000201\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9798/10000 (97.98%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9798/10000 (97.98%)\n",
            "\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.000101\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.000101\n",
            "Train Epoch: 69 [24000/60000 (40%)]\tLoss: 0.000353\n",
            "Train Epoch: 69 [24000/60000 (40%)]\tLoss: 0.000353\n",
            "Train Epoch: 69 [48000/60000 (80%)]\tLoss: 0.004210\n",
            "Train Epoch: 69 [48000/60000 (80%)]\tLoss: 0.004210\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9791/10000 (97.91%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9791/10000 (97.91%)\n",
            "\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.007974\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.007974\n",
            "Train Epoch: 70 [24000/60000 (40%)]\tLoss: 0.000075\n",
            "Train Epoch: 70 [24000/60000 (40%)]\tLoss: 0.000075\n",
            "Train Epoch: 70 [48000/60000 (80%)]\tLoss: 0.000698\n",
            "Train Epoch: 70 [48000/60000 (80%)]\tLoss: 0.000698\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000532\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000532\n",
            "Train Epoch: 71 [24000/60000 (40%)]\tLoss: 0.000190\n",
            "Train Epoch: 71 [24000/60000 (40%)]\tLoss: 0.000190\n",
            "Train Epoch: 71 [48000/60000 (80%)]\tLoss: 0.001415\n",
            "Train Epoch: 71 [48000/60000 (80%)]\tLoss: 0.001415\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000207\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000207\n",
            "Train Epoch: 72 [24000/60000 (40%)]\tLoss: 0.002511\n",
            "Train Epoch: 72 [24000/60000 (40%)]\tLoss: 0.002511\n",
            "Train Epoch: 72 [48000/60000 (80%)]\tLoss: 0.000888\n",
            "Train Epoch: 72 [48000/60000 (80%)]\tLoss: 0.000888\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9798/10000 (97.98%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9798/10000 (97.98%)\n",
            "\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.000482\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.000482\n",
            "Train Epoch: 73 [24000/60000 (40%)]\tLoss: 0.000066\n",
            "Train Epoch: 73 [24000/60000 (40%)]\tLoss: 0.000066\n",
            "Train Epoch: 73 [48000/60000 (80%)]\tLoss: 0.006894\n",
            "Train Epoch: 73 [48000/60000 (80%)]\tLoss: 0.006894\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.001075\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.001075\n",
            "Train Epoch: 74 [24000/60000 (40%)]\tLoss: 0.003117\n",
            "Train Epoch: 74 [24000/60000 (40%)]\tLoss: 0.003117\n",
            "Train Epoch: 74 [48000/60000 (80%)]\tLoss: 0.000536\n",
            "Train Epoch: 74 [48000/60000 (80%)]\tLoss: 0.000536\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.000434\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.000434\n",
            "Train Epoch: 75 [24000/60000 (40%)]\tLoss: 0.001994\n",
            "Train Epoch: 75 [24000/60000 (40%)]\tLoss: 0.001994\n",
            "Train Epoch: 75 [48000/60000 (80%)]\tLoss: 0.002053\n",
            "Train Epoch: 75 [48000/60000 (80%)]\tLoss: 0.002053\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.000245\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.000245\n",
            "Train Epoch: 76 [24000/60000 (40%)]\tLoss: 0.002111\n",
            "Train Epoch: 76 [24000/60000 (40%)]\tLoss: 0.002111\n",
            "Train Epoch: 76 [48000/60000 (80%)]\tLoss: 0.000262\n",
            "Train Epoch: 76 [48000/60000 (80%)]\tLoss: 0.000262\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.002778\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.002778\n",
            "Train Epoch: 77 [24000/60000 (40%)]\tLoss: 0.000337\n",
            "Train Epoch: 77 [24000/60000 (40%)]\tLoss: 0.000337\n",
            "Train Epoch: 77 [48000/60000 (80%)]\tLoss: 0.000228\n",
            "Train Epoch: 77 [48000/60000 (80%)]\tLoss: 0.000228\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.002537\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.002537\n",
            "Train Epoch: 78 [24000/60000 (40%)]\tLoss: 0.000063\n",
            "Train Epoch: 78 [24000/60000 (40%)]\tLoss: 0.000063\n",
            "Train Epoch: 78 [48000/60000 (80%)]\tLoss: 0.004209\n",
            "Train Epoch: 78 [48000/60000 (80%)]\tLoss: 0.004209\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000110\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000110\n",
            "Train Epoch: 79 [24000/60000 (40%)]\tLoss: 0.000284\n",
            "Train Epoch: 79 [24000/60000 (40%)]\tLoss: 0.000284\n",
            "Train Epoch: 79 [48000/60000 (80%)]\tLoss: 0.015779\n",
            "Train Epoch: 79 [48000/60000 (80%)]\tLoss: 0.015779\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.003534\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.003534\n",
            "Train Epoch: 80 [24000/60000 (40%)]\tLoss: 0.002506\n",
            "Train Epoch: 80 [24000/60000 (40%)]\tLoss: 0.002506\n",
            "Train Epoch: 80 [48000/60000 (80%)]\tLoss: 0.000520\n",
            "Train Epoch: 80 [48000/60000 (80%)]\tLoss: 0.000520\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000852\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000852\n",
            "Train Epoch: 81 [24000/60000 (40%)]\tLoss: 0.000902\n",
            "Train Epoch: 81 [24000/60000 (40%)]\tLoss: 0.000902\n",
            "Train Epoch: 81 [48000/60000 (80%)]\tLoss: 0.001463\n",
            "Train Epoch: 81 [48000/60000 (80%)]\tLoss: 0.001463\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.001418\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.001418\n",
            "Train Epoch: 82 [24000/60000 (40%)]\tLoss: 0.001052\n",
            "Train Epoch: 82 [24000/60000 (40%)]\tLoss: 0.001052\n",
            "Train Epoch: 82 [48000/60000 (80%)]\tLoss: 0.000896\n",
            "Train Epoch: 82 [48000/60000 (80%)]\tLoss: 0.000896\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.011783\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.011783\n",
            "Train Epoch: 83 [24000/60000 (40%)]\tLoss: 0.000198\n",
            "Train Epoch: 83 [24000/60000 (40%)]\tLoss: 0.000198\n",
            "Train Epoch: 83 [48000/60000 (80%)]\tLoss: 0.023666\n",
            "Train Epoch: 83 [48000/60000 (80%)]\tLoss: 0.023666\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.001192\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.001192\n",
            "Train Epoch: 84 [24000/60000 (40%)]\tLoss: 0.003121\n",
            "Train Epoch: 84 [24000/60000 (40%)]\tLoss: 0.003121\n",
            "Train Epoch: 84 [48000/60000 (80%)]\tLoss: 0.000070\n",
            "Train Epoch: 84 [48000/60000 (80%)]\tLoss: 0.000070\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000965\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000965\n",
            "Train Epoch: 85 [24000/60000 (40%)]\tLoss: 0.002265\n",
            "Train Epoch: 85 [24000/60000 (40%)]\tLoss: 0.002265\n",
            "Train Epoch: 85 [48000/60000 (80%)]\tLoss: 0.000533\n",
            "Train Epoch: 85 [48000/60000 (80%)]\tLoss: 0.000533\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.006645\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.006645\n",
            "Train Epoch: 86 [24000/60000 (40%)]\tLoss: 0.000056\n",
            "Train Epoch: 86 [24000/60000 (40%)]\tLoss: 0.000056\n",
            "Train Epoch: 86 [48000/60000 (80%)]\tLoss: 0.000892\n",
            "Train Epoch: 86 [48000/60000 (80%)]\tLoss: 0.000892\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.004561\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.004561\n",
            "Train Epoch: 87 [24000/60000 (40%)]\tLoss: 0.000063\n",
            "Train Epoch: 87 [24000/60000 (40%)]\tLoss: 0.000063\n",
            "Train Epoch: 87 [48000/60000 (80%)]\tLoss: 0.001143\n",
            "Train Epoch: 87 [48000/60000 (80%)]\tLoss: 0.001143\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.000105\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.000105\n",
            "Train Epoch: 88 [24000/60000 (40%)]\tLoss: 0.000333\n",
            "Train Epoch: 88 [24000/60000 (40%)]\tLoss: 0.000333\n",
            "Train Epoch: 88 [48000/60000 (80%)]\tLoss: 0.000202\n",
            "Train Epoch: 88 [48000/60000 (80%)]\tLoss: 0.000202\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000322\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000322\n",
            "Train Epoch: 89 [24000/60000 (40%)]\tLoss: 0.002039\n",
            "Train Epoch: 89 [24000/60000 (40%)]\tLoss: 0.002039\n",
            "Train Epoch: 89 [48000/60000 (80%)]\tLoss: 0.001766\n",
            "Train Epoch: 89 [48000/60000 (80%)]\tLoss: 0.001766\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000706\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000706\n",
            "Train Epoch: 90 [24000/60000 (40%)]\tLoss: 0.000078\n",
            "Train Epoch: 90 [24000/60000 (40%)]\tLoss: 0.000078\n",
            "Train Epoch: 90 [48000/60000 (80%)]\tLoss: 0.000019\n",
            "Train Epoch: 90 [48000/60000 (80%)]\tLoss: 0.000019\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000207\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000207\n",
            "Train Epoch: 91 [24000/60000 (40%)]\tLoss: 0.000185\n",
            "Train Epoch: 91 [24000/60000 (40%)]\tLoss: 0.000185\n",
            "Train Epoch: 91 [48000/60000 (80%)]\tLoss: 0.000243\n",
            "Train Epoch: 91 [48000/60000 (80%)]\tLoss: 0.000243\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000327\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000327\n",
            "Train Epoch: 92 [24000/60000 (40%)]\tLoss: 0.000194\n",
            "Train Epoch: 92 [24000/60000 (40%)]\tLoss: 0.000194\n",
            "Train Epoch: 92 [48000/60000 (80%)]\tLoss: 0.002009\n",
            "Train Epoch: 92 [48000/60000 (80%)]\tLoss: 0.002009\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000629\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000629\n",
            "Train Epoch: 93 [24000/60000 (40%)]\tLoss: 0.000102\n",
            "Train Epoch: 93 [24000/60000 (40%)]\tLoss: 0.000102\n",
            "Train Epoch: 93 [48000/60000 (80%)]\tLoss: 0.000264\n",
            "Train Epoch: 93 [48000/60000 (80%)]\tLoss: 0.000264\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9801/10000 (98.01%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9801/10000 (98.01%)\n",
            "\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.000059\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.000059\n",
            "Train Epoch: 94 [24000/60000 (40%)]\tLoss: 0.038241\n",
            "Train Epoch: 94 [24000/60000 (40%)]\tLoss: 0.038241\n",
            "Train Epoch: 94 [48000/60000 (80%)]\tLoss: 0.000489\n",
            "Train Epoch: 94 [48000/60000 (80%)]\tLoss: 0.000489\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.040664\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.040664\n",
            "Train Epoch: 95 [24000/60000 (40%)]\tLoss: 0.000841\n",
            "Train Epoch: 95 [24000/60000 (40%)]\tLoss: 0.000841\n",
            "Train Epoch: 95 [48000/60000 (80%)]\tLoss: 0.005944\n",
            "Train Epoch: 95 [48000/60000 (80%)]\tLoss: 0.005944\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000321\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000321\n",
            "Train Epoch: 96 [24000/60000 (40%)]\tLoss: 0.000586\n",
            "Train Epoch: 96 [24000/60000 (40%)]\tLoss: 0.000586\n",
            "Train Epoch: 96 [48000/60000 (80%)]\tLoss: 0.000413\n",
            "Train Epoch: 96 [48000/60000 (80%)]\tLoss: 0.000413\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.002268\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.002268\n",
            "Train Epoch: 97 [24000/60000 (40%)]\tLoss: 0.000043\n",
            "Train Epoch: 97 [24000/60000 (40%)]\tLoss: 0.000043\n",
            "Train Epoch: 97 [48000/60000 (80%)]\tLoss: 0.000649\n",
            "Train Epoch: 97 [48000/60000 (80%)]\tLoss: 0.000649\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.001274\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.001274\n",
            "Train Epoch: 98 [24000/60000 (40%)]\tLoss: 0.003483\n",
            "Train Epoch: 98 [24000/60000 (40%)]\tLoss: 0.003483\n",
            "Train Epoch: 98 [48000/60000 (80%)]\tLoss: 0.000270\n",
            "Train Epoch: 98 [48000/60000 (80%)]\tLoss: 0.000270\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000360\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000360\n",
            "Train Epoch: 99 [24000/60000 (40%)]\tLoss: 0.001445\n",
            "Train Epoch: 99 [24000/60000 (40%)]\tLoss: 0.001445\n",
            "Train Epoch: 99 [48000/60000 (80%)]\tLoss: 0.000230\n",
            "Train Epoch: 99 [48000/60000 (80%)]\tLoss: 0.000230\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.054628\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.054628\n",
            "Train Epoch: 100 [24000/60000 (40%)]\tLoss: 0.000969\n",
            "Train Epoch: 100 [24000/60000 (40%)]\tLoss: 0.000969\n",
            "Train Epoch: 100 [48000/60000 (80%)]\tLoss: 0.000134\n",
            "Train Epoch: 100 [48000/60000 (80%)]\tLoss: 0.000134\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "\n",
            "Test set: Average Loss: 0.0001, Accuracy: 9808/10000 (98.08%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oesDkc8FUqsd",
        "colab_type": "text"
      },
      "source": [
        "#### 3.3. Comparing the results\n",
        "\n",
        "MNIST 데이터셋을 바탕으로 BNN을 트레이닝한 결과를 보았을 때 결과는 다음과 같았다. DNN(Deep Neural Network)에서 최대 정확도가 98.17%이고, BNN(Binarized Neural Network) 환경에서 최대 97.7%의 정확도를 가진 것을 확인할 수 있다(이 내용은 실험시 소폭 달라질 수 있음). DNN과 BNN의 정확도 차이가 약 0.47% 인 것으로 나타난 것을 볼 수 있다. 이는 Network의 Parameter를 이진화시킴으로써 크기를 크게 줄인 반면, 정확도는 소폭 감소하여 성능이 유지되는 것을 알 수 있다.\n",
        "\n",
        "BNN Parameter를 출력하여 네트워크의 Parameter가 Binarized 됬는지 확인할 수 있다. 아래 출력된 결과를 통해 1과 -1이 weight의 값으로 사용된 것을 볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoqLpXZ4ThgN",
        "colab_type": "code",
        "outputId": "55dcf706-310f-4793-96c1-2c5832fda54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"Binarized Nerual Netowork: \", binary_best,\"%\", \"\\nDeep Neural Network: \", normal_best, \"%\\n\")\n",
        "print(\"Example Parameters in BNN\\n\",binarized_model.fc2.weight)\n",
        "print(\"\\nExample Parameters in DNN\\n\", normal_model.fc2.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binarized Nerual Netowork:  97.7 % \n",
            "Deep Neural Network:  98.17 %\n",
            "\n",
            "Example Parameters in BNN\n",
            " Parameter containing:\n",
            "tensor([[-1., -1.,  1.,  ..., -1., -1., -1.],\n",
            "        [-1.,  1.,  1.,  ...,  1., -1.,  1.],\n",
            "        [-1., -1., -1.,  ..., -1.,  1.,  1.],\n",
            "        ...,\n",
            "        [ 1.,  1., -1.,  ...,  1., -1.,  1.],\n",
            "        [-1.,  1., -1.,  ..., -1.,  1., -1.],\n",
            "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "\n",
            "Example Parameters in DNN\n",
            " Parameter containing:\n",
            "tensor([[-1.0074e-03, -5.9346e-05, -2.5056e-02,  ..., -2.7849e-02,\n",
            "          1.6668e-02, -6.0850e-03],\n",
            "        [ 4.8277e-02,  1.7304e-02, -7.2783e-03,  ...,  2.7869e-02,\n",
            "          3.1388e-02, -3.0012e-02],\n",
            "        [-1.5052e-02, -5.4204e-03, -5.8841e-03,  ...,  4.3406e-02,\n",
            "         -2.5258e-02,  9.0726e-03],\n",
            "        ...,\n",
            "        [-1.0635e-02,  1.1019e-02, -3.4251e-03,  ..., -2.3202e-02,\n",
            "          6.0548e-03, -4.1337e-03],\n",
            "        [ 1.4162e-03,  1.1785e-02, -2.1178e-02,  ...,  3.0263e-02,\n",
            "          1.6023e-02,  4.3089e-02],\n",
            "        [-1.3955e-02,  2.5541e-02,  9.7548e-03,  ...,  2.4808e-02,\n",
            "         -8.8138e-03, -1.7275e-02]], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPYgVwfrRGo2",
        "colab_type": "text"
      },
      "source": [
        "## 4\\. Appendix\n",
        "\n",
        "보고서에서 구현한 내용을 가속기로 설계하여 실제 FPGA 보드에서 구현할 수 있다[2][3]. 다만 FPGA 가속기로 설계하는 과정은 본 과목인 머신 러닝과 크게 관련이 없는 관계로, 본 보고서에 기술하지 않았다.\n",
        "\n",
        "![pynq-z2](https://media-cdn.seeedstudio.site/media/catalog/product/cache/9d0ce51a71ce6a79dfa2a98d65a0f0bd/0/3/03_pynq-z2.jpg)\n",
        "\n",
        "부록에는 위에서 정의한 BNN 네트워크를 가속기로 구현하였을 때, 임베디드 FPGA 보드에서 딥러닝이 연산 성능을 테스트하는 노트북을 담았다. 아래 설명된 노트는 본 연구실에서 사용한 노트북을 참조한 것이다. 가속기로 사용한 보드는 TUL사에서 공급하는 PYNQ-Z2 보드이다. FPGA 칩으로는 Xilinx의 ZYNQ-7000SoC 가 내장되어있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVx82tUrOx7k",
        "colab_type": "text"
      },
      "source": [
        "### **BNN on PYNQ-Z2**\n",
        "\n",
        "This notebook covers how to use Binary Neural Networks on Pynq[2]. \n",
        "It shows an example of handwritten digit recognition using a binarized neural network composed of 4 fully connected layers with 1024 neurons each, trained on the MNIST dataset of handwritten digits. \n",
        "In order to reproduce this notebook, you will need an external USB Camera connected to the PYNQ Board.\n",
        "\n",
        "### 4.1. Import the package\n",
        "\n",
        "```python\n",
        "import bnn\n",
        "```\n",
        "\n",
        "### 4.2. Checking available parameters\n",
        "\n",
        "By default the following trained parameters are available for LFC network using 1 bit for weights and 1 threshold for activation:\n",
        "\n",
        "\n",
        "```python\n",
        "print(bnn.available_params(bnn.NETWORK_LFCW1A1))\n",
        "```\n",
        "\n",
        "    ['mnist', 'chars_merged']\n",
        "\n",
        "\n",
        "Two sets of weights are available for the LFCW1A1 network, the MNIST and one for character recognition (NIST).\n",
        "\n",
        "### 4.3. Instantiate the classifier\n",
        "\n",
        "Creating a classifier will automatically download the correct bitstream onto the device and load the weights trained on the specified dataset. This example works with the LFCW1A1 for inferring MNIST handwritten digits.\n",
        "Passing a runtime attribute will allow to choose between hardware accelerated or pure software inference.\n",
        "\n",
        "\n",
        "```python\n",
        "hw_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A1,\"mnist\",bnn.RUNTIME_HW)\n",
        "sw_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A1,\"mnist\",bnn.RUNTIME_SW)\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "print(hw_classifier.classes)\n",
        "```\n",
        "\n",
        "    ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "\n",
        "### 4.4. Load the image from the camera\n",
        "\n",
        "The image is captured from the external USB camera and stored locally. The image is then enhanced in contract and brightness to remove background noise. \n",
        "The resulting image should show the digit on a white background:\n",
        "\n",
        "![field](https://trello-attachments.s3.amazonaws.com/5dafff41d7f4747dcbf310a1/5def2cb3fc678a823ccd45db/532f51b7f9843dad907bff8f01869ee4/IMG_4321.jpg)\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "from PIL import Image as PIL_Image\n",
        "from PIL import ImageEnhance\n",
        "from PIL import ImageOps\n",
        "\n",
        "# says we capture an image from a webcam\n",
        "cap = cv2.VideoCapture(0) \n",
        "_ , cv2_im = cap.read(0)\n",
        "i = 0\n",
        "while(_ == False):\n",
        "    _ , cv2_im = cap.read(0)\n",
        "    i += 1\n",
        "    if(i >= 100):\n",
        "        i = 0\n",
        "        print(_)\n",
        "cv2_im = cv2.cvtColor(cv2_im,cv2.COLOR_BGR2RGB)\n",
        "img = PIL_Image.fromarray(cv2_im).convert(\"L\") \n",
        "#Image enhancement                \n",
        "contr = ImageEnhance.Contrast(img)\n",
        "img = contr.enhance(3)                                                    # The enhancement values (contrast and brightness) \n",
        "bright = ImageEnhance.Brightness(img)                                     # depends on backgroud, external lights etc\n",
        "img = bright.enhance(4.0)          \n",
        "                                            # Rotate the image (depending on camera orientation)\n",
        "#Adding a border for future cropping\n",
        "img = ImageOps.expand(img,border=80,fill='white') \n",
        "img\n",
        "\n",
        "```\n",
        "![png](https://trello-attachments.s3.amazonaws.com/5dafff41d7f4747dcbf310a1/5def2cb3fc678a823ccd45db/a87873ce17d41147dfbd3823821d44dc/output_9_0.png)\n",
        "```python\n",
        "width = img.size[0]\n",
        "height = img.size[1]\n",
        "\n",
        "m_width = 250\n",
        "m_height = int(height*(m_width/width))\n",
        "\n",
        "w_diff = int((width - m_width)/2)\n",
        "h_diff = int((height - m_height)/2)\n",
        "\n",
        "data = img.crop((w_diff,h_diff,w_diff+m_width,h_diff+m_height))\n",
        "print(data.size)\n",
        "data\n",
        "```\n",
        "\n",
        "    (250, 200)\n",
        "\n",
        "![png](https://trello-attachments.s3.amazonaws.com/5dafff41d7f4747dcbf310a1/5def2cb3fc678a823ccd45db/8c5e22980d3ac7786807c484731c07b4/output_10_1.png)\n",
        "\n",
        "\n",
        "\n",
        "### 4.5. Crop and scale the image\n",
        "\n",
        "The center of mass of the image is evaluated to properly crop the image and extract the written digit only. \n",
        "\n",
        "\n",
        "```python\n",
        "from PIL import Image as PIL_Image\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy import misc\n",
        "\n",
        "#Find bounding box  \n",
        "# 테두리 잘라서 숫자만 남기는 부분\n",
        "inverted = ImageOps.invert(data)  \n",
        "box = inverted.getbbox()\n",
        "img_new = data.crop(box)\n",
        "\n",
        "#Resize and add padding blacks\n",
        "sqr_size = 18\n",
        "width, height = img_new.size  \n",
        "ratio = min((sqr_size/height), (sqr_size/width))  \n",
        "background = PIL_Image.new('RGB', (sqr_size,sqr_size), (255,255,255))  \n",
        "if(height == width):  \n",
        "    img_new = img_new.resize((sqr_size,sqr_size))  \n",
        "elif(height>width):  \n",
        "    img_new = img_new.resize((int(width*ratio),sqr_size))  \n",
        "    background.paste(img_new, (int((sqr_size-img_new.size[0])/2),int((sqr_size-img_new.size[1])/2)))  \n",
        "else:  \n",
        "    img_new = img_new.resize((sqr_size, int(height*ratio)))  \n",
        "    background.paste(img_new, (int((sqr_size-img_new.size[0])/2),int((sqr_size-img_new.size[1])/2)))  \n",
        "  \n",
        "\n",
        "background  \n",
        "img_data=np.asarray(background)  \n",
        "img_data = img_data[:,:,0]  \n",
        "\n",
        "\n",
        "\n",
        "img_new\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![png](https://trello-attachments.s3.amazonaws.com/5dafff41d7f4747dcbf310a1/5def2cb3fc678a823ccd45db/5210fbb92784d8337a92fd23247f2f35/output_12_0.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "padd_img = np.zeros((28,28))\n",
        "\n",
        "diff = int((28 - sqr_size) / 2)\n",
        "\n",
        "for i in range(0,28):\n",
        "    if i < diff:\n",
        "        padd_img[i] = [255 for i in range(0,28)]\n",
        "    elif i > 27-diff:\n",
        "        padd_img[i] = [255 for i in range(0,28)]\n",
        "    else:\n",
        "        temp = [255 for i in range(diff)]\n",
        "        temp.extend(img_data[i-diff])\n",
        "        temp.extend([255 for i in range(diff)])\n",
        "        padd_img[i] = temp\n",
        "padd_img.shape\n",
        "\n",
        "misc.imsave('/home/xilinx/img_webcam_mnist.png', padd_img) \n",
        "```\n",
        "\n",
        "### 4.6. Convert to BNN input format\n",
        "\n",
        "The image is resized to comply with the MNIST standard. The image is resized at 28x28 pixels and the colors inverted. \n",
        "\n",
        "\n",
        "```python\n",
        "from array import *\n",
        "from PIL import Image as PIL_Image\n",
        "from PIL import ImageOps\n",
        "img_load = PIL_Image.open('/home/xilinx/img_webcam_mnist.png').convert(\"L\")  \n",
        "# Convert to BNN input format  \n",
        "# The image is resized to comply with the MNIST standard. The image is resized at 28x28 pixels and the colors inverted.   \n",
        "  \n",
        "#Resize the image and invert it (white on black)  흑백 반전\n",
        "smallimg = ImageOps.invert(img_load)  \n",
        "smallimg = smallimg.rotate(0)  \n",
        "  \n",
        "data_image = array('B')  \n",
        "  \n",
        "pixel = smallimg.load()  \n",
        "for x in range(0,28):  \n",
        "    for y in range(0,28):  \n",
        "        if(pixel[y,x] == 255):  \n",
        "            data_image.append(255)  \n",
        "        else:  \n",
        "            data_image.append(1)  \n",
        "          \n",
        "# Setting up the header of the MNIST format file - Required as the hardware is designed for MNIST dataset         \n",
        "hexval = \"{0:#0{1}x}\".format(1,6)  \n",
        "header = array('B')  \n",
        "header.extend([0,0,8,1,0,0])  \n",
        "header.append(int('0x'+hexval[2:][:2],16))  \n",
        "header.append(int('0x'+hexval[2:][2:],16))  \n",
        "header.extend([0,0,0,28,0,0,0,28])  \n",
        "header[3] = 3 # Changing MSB for image data (0x00000803)  \n",
        "data_image = header + data_image  \n",
        "output_file = open('/home/xilinx/img_webcam_mnist_processed', 'wb')  \n",
        "data_image.tofile(output_file)  \n",
        "output_file.close()   \n",
        "smallimg\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![png](https://trello-attachments.s3.amazonaws.com/5dafff41d7f4747dcbf310a1/5def2cb3fc678a823ccd45db/91256c2ba4a08d542fe730fa53436137/output_15_0.png)\n",
        "\n",
        "\n",
        "\n",
        "### 4.7. Launching BNN in hardware\n",
        "\n",
        "The image is passed in the PL and the inference is performed. Use `classify_mnist` to classify a single mnist formatted picture.\n",
        "\n",
        "\n",
        "```python\n",
        "class_out = hw_classifier.classify_mnist(\"/home/xilinx/img_webcam_mnist_processed\")\n",
        "print(\"Class number: {0}\".format(class_out))\n",
        "print(\"Class name: {0}\".format(hw_classifier.class_name(class_out)))\n",
        "```\n",
        "\n",
        "    Inference took 24.00 microseconds\n",
        "    Classification rate: 41666.67 images per second\n",
        "    Class number: 4\n",
        "    Class name: 4\n",
        "\n",
        "\n",
        "### 4.8. Launching BNN in software\n",
        "\n",
        "The inference on the same image is performed in sofware on the ARM core\n",
        "\n",
        "\n",
        "```python\n",
        "class_out=sw_classifier.classify_mnist(\"/home/xilinx/img_webcam_mnist_processed\")\n",
        "print(\"Class number: {0}\".format(class_out))\n",
        "print(\"Class name: {0}\".format(hw_classifier.class_name(class_out)))\n",
        "```\n",
        "\n",
        "    Inference took 84201.00 microseconds\n",
        "    Classification rate: 11.88 images per second\n",
        "    Class number: 4\n",
        "    Class name: 4\n",
        "\n",
        "\n",
        "### 4.9. Reset the device\n",
        "\n",
        "\n",
        "```python\n",
        "from pynq import Xlnk\n",
        "\n",
        "xlnk = Xlnk()\n",
        "xlnk.xlnk_reset()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxGshZrsHylz",
        "colab_type": "text"
      },
      "source": [
        "## 5\\. References\n",
        "\n",
        ">[1] Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., & Bengio, Y. (2016). \"Binarized neural networks: Training deep neural networks with weights and activations constrained to +1 or -1\". arXiv preprint arXiv:1602.02830.\n",
        ">\n",
        ">[2] Umuroglu, Y., Fraser, N. J., Gambardella, G., Blott, M., Leong, P., Jahre, M., & Vissers, K. (2017, February). \"Finn: A framework for fast, scalable binarized neural network inference\". In Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (pp. 65-74). ACM.\n",
        ">\n",
        ">[3] Chae Eon Lim, Geun Su Song, Yun Hye Park., Yoon Seong Lim, Kang Yi, “FPGA Accelerator Design for Handwritten Digit Recognition in Embedded System”, 2019 Fall Conference on Korea Multimedia Society\n",
        "\n"
      ]
    }
  ]
}